{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab5a51be",
   "metadata": {},
   "source": [
    "# Introductions for the Prediction and Evaluation\n",
    "\n",
    "<font color ='red'> **NOTE!** </font> *Before you start testing the models, especially when you have made predictions multiple times, check the saving directory that it either contains the predictions you have made in the previous iteration or is empty. If you use different test data with the same yaml file, you might end up having predictions from different csv files and evaluation doesn't work. Mind this especially, if you get an **AssertionError**.*\n",
    "\n",
    "As with the training phase, yaml files are also used in the prediction and evaluation phase. They have a structure as follows (`prediction_smoke.yaml`)\n",
    "\n",
    "```\n",
    "# INITIAL SETTINGS\n",
    "test_file: 'test_split0.csv'\n",
    "model: 'split0_0.pth'\n",
    "```\n",
    "\n",
    "where `test_file` is the csv file of the test data and `model` is the file of the trained model.\n",
    "\n",
    "The script for this phase is `run_model.py`. You should first check the paths `csv_root` and `data_root` that they point to the right locations in the `data` directory (and its subdirectories). The attribute `csv_root` is to find the csv file of the test data and `data_root` is to find the data. `model` will be searched from the `experiments` directory automatically so only the name of the file is nessessary.\n",
    "\n",
    "<font color ='red'>**NOTE!**</font> The attribute `args.device_count` should be considered. It refers to the number of GPUs which are used in prediction, as in the training phase.\n",
    "\n",
    "The predictions are saved as csv files with the following structure\n",
    "\n",
    "```\n",
    "#Record ID\n",
    "164889003, 270492004, 164909002, 426783006, 59118001, 284470004,  164884008,\n",
    "        1,         1,         0,         0,         0,        0,          0,        \n",
    "      0.9,       0.6,       0.2,       0.05,      0.2,      0.35,       0.35,  \n",
    "```\n",
    "\n",
    "where the first row, `#Record ID`, refers to the file name from which the prediction is made, and the second to the class labels used in SNOMED CT codes, and the third row to the predicted label in binary form (1 - patient is predicted to have the diagnosis above, and 0 - the opposite), and the fourth row to the probability scores for each predicted label. \n",
    "\n",
    "The script performs the evaluation automatically after the predictions are made. In the evaluation phase, `metrics.py` is used from `/src/modeling/` to compute the wanted metrics. The function `evaluate_predictions(test_data, pred_dir)` is called where the parameter `test_data` refers to the location of the test data, and the parameter `pred_dir` to the location of the predictions made from the test data. These parameters refer to the arguments `args.test_path` and `args.output_dir` in the script `run_model.py`. \n",
    "\n",
    "The evaluation metrics will be saved in the same directory as the predictions and is in the form of a `pickle` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e87a9d",
   "metadata": {},
   "source": [
    "### Terminal commands\n",
    "\n",
    "Terminal command for the phase is the following\n",
    "\n",
    "```\n",
    "python run_model.py prediction_smoke.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349e3950",
   "metadata": {},
   "source": [
    "## Example: Smoke testing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba3594d",
   "metadata": {},
   "source": [
    "The yaml file for smoke testing --- `prediction_smoke.yaml` --- is available in `/configs/predicting/`. Make sure the model is trained first and is named as `train_smoke.pth`! Obviously, perform training explained in the notebook [Introductions for Training a Model](3_introductions_training.ipynb) first.\n",
    "\n",
    "*And before anything, check if there exists a directory named `prediction_smoke` in the `experiments` directory. If there are other predictions made and they are not the ones from the files listed below, evaluation won't work correctly. Mind this especially when you get an **AssertionError**.*\n",
    "\n",
    "The csv file `test_split0.csv` has the following structure\n",
    "\n",
    "```\n",
    "path,age,gender,fs,426783006,426177001,164934002,427084000,164890007,39732003,164889003,59931005,427393009,270492004\n",
    "./data/physionet_preprocessed_smoke/CPSC_CPSC-Extra/A0004_preprocessed.mat,45.0,Male,500.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0\n",
    "./data/physionet_preprocessed_smoke/CPSC_CPSC-Extra/A0003_preprocessed.mat,81.0,Female,500.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0\n",
    "./data/physionet_preprocessed_smoke/CPSC_CPSC-Extra/A0007_preprocessed.mat,74.0,Male,500.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0\n",
    "./data/physionet_preprocessed_smoke/CPSC_CPSC-Extra/Q0001_preprocessed.mat,53.0,Male,500.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
    "./data/physionet_preprocessed_smoke/CPSC_CPSC-Extra/A0009_preprocessed.mat,81.0,Male,500.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0\n",
    "./data/physionet_preprocessed_smoke/CPSC_CPSC-Extra/A0002_preprocessed.mat,49.0,Female,500.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
    "```\n",
    "\n",
    "so total of six files are considered as test data. All of them are from the `CPSC` and `CPSC-Extra` databases.\n",
    "\n",
    "Let's then check the paths and the number of devices used in `run_model.py` to point the right locations. For testing, they are as follows\n",
    "\n",
    "```\n",
    "csv_root = './data/split_csvs/physionet_stratified_smoke/'\n",
    "data_root = './data/physionet_preprocessed_smoke/'\n",
    "\n",
    "args.device_count = 1\n",
    "```\n",
    "\n",
    "<font color = red>**NOTE!**</font> <font color = green> **Here, the** `data_root` **attribute is set with the assumption that *the data used is preprocessed*. If that's not the case, you should use, for example, the original data directory, such as** `./data/physionet_data_smoke/`. The paths for ECGs will be different in the csv files based on the fact if the data is preprocessed or not.</font> \n",
    "\n",
    "Then you can just run the command to make the predictions with the trained model saved as `train_smoke.pth` as\n",
    "\n",
    "```\n",
    "python run_model.py prediction_smoke.yaml\n",
    "```\n",
    "\n",
    "The predictions can be found in the `prediction_smoke` subdirectory of the `experiments` directory. Each prediction is named after the original file name from which the predictions have been made. In smoke testing, they are as follows\n",
    "\n",
    "```\n",
    "A0002_preprocessed.csv\n",
    "A0003_preprocessed.csv\n",
    "A0004_preprocessed.csv\n",
    "A0007_preprocessed.csv\n",
    "A0009_preprocessed.csv\n",
    "Q0001_preprocessed.csv\n",
    "```\n",
    "\n",
    "Each have the structure of the one presented above. \n",
    "\n",
    "After all the predictions are made, the scripts calls `evaluate_predictions(test_data, pred_dir)` to evaluate these predictions. Such metrics are shown in terminal as follows\n",
    "\n",
    "```\n",
    "Micro Average Precision: 0.11131725417439703\n",
    "Micro AUROC:             0.5205811138014528\n",
    "Accuracy:                0.0\n",
    "Micro F1-score:          0.14285714285714285\n",
    "```\n",
    "\n",
    "These metrics are now saved in the file `eval_history.pickle` and can be found in the same directory as the predictions are located."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
