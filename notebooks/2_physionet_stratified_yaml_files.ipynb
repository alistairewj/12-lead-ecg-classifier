{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dca53a29",
   "metadata": {},
   "source": [
    "# Yaml files of Stratified Split for Training and Prediction\n",
    "\n",
    "With this notebook, you can create the yaml files needed in training and prediction with a data split which is made  using **stratifiction**. More detailed information about the stratified data split itself is available in the notebook [Introductions for Data Handling](1_introductions_data_handling.ipynb).\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b88b00d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# PARAMETERS TO CREATE STRATIFIED YAML FILES  \n",
    "# ------------------------------------------\n",
    "\n",
    "# From where to load the csv files of stratified split\n",
    "csv_path = os.path.join('../data/split_csvs/', 'physionet_stratified_smoke')\n",
    "\n",
    "# Where to save the training yaml files\n",
    "train_yaml_save_path = os.path.join('../configs/training', 'train_stratified_smoke')\n",
    "\n",
    "# Where to save the testing yaml files\n",
    "test_yaml_save_path = os.path.join('../configs/predicting', 'prediction_stratified_smoke')\n",
    "\n",
    "# Parameters for training yaml files\n",
    "batch_size = 10\n",
    "num_workers = 0\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e256917d",
   "metadata": {},
   "source": [
    "The csv files of the stratified splits should be found `/data/split_csvs/`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c57b038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_split0.csv\n",
      "train_split0_0.csv\n",
      "train_split0_1.csv\n",
      "train_split0_2.csv\n",
      "train_split0_3.csv\n",
      "val_split0_0.csv\n",
      "val_split0_1.csv\n",
      "val_split0_2.csv\n",
      "val_split0_3.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Stratified csv files\n",
    "csv_files = sorted([file for file in os.listdir(csv_path) if not file.startswith('.')])\n",
    "\n",
    "print(*csv_files, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5773a438",
   "metadata": {},
   "source": [
    "Let's combine the right training, validation and prediction splits first, e.g., `train_split0_0.csv`, `val_split0_0.csv` and `test_split0.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0dedbb0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 training and validatin pairs\n",
      "('train_split0_0.csv', 'val_split0_0.csv')\n",
      "('train_split0_1.csv', 'val_split0_1.csv')\n",
      "('train_split0_2.csv', 'val_split0_2.csv')\n",
      "('train_split0_3.csv', 'val_split0_3.csv')\n",
      "\n",
      "Training, validation and testing pairs\n",
      "['train_split0_0.csv', 'val_split0_0.csv', 'test_split0.csv']\n",
      "['train_split0_1.csv', 'val_split0_1.csv', 'test_split0.csv']\n",
      "['train_split0_2.csv', 'val_split0_2.csv', 'test_split0.csv']\n",
      "['train_split0_3.csv', 'val_split0_3.csv', 'test_split0.csv']\n",
      "\n",
      "Total of 4 training, validation and testing sets\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# First, divide train and validation splits into own lists\n",
    "train_files = [file for file in csv_files if 'train' in file]\n",
    "val_files = [file for file in csv_files if 'val' in file]\n",
    "\n",
    "# Zip these two and convert to list since they should be sorted similarly\n",
    "train_val_pair = list(zip(train_files, val_files))\n",
    "print('First 5 training and validatin pairs')\n",
    "print(*train_val_pair[:5], sep='\\n')\n",
    "print()\n",
    "\n",
    "# Seems right based on the print:\n",
    "# Add the prediction fi\n",
    "test_files = [file for file in csv_files if 'test' in file]\n",
    "\n",
    "split_nums = [] # These are for yaml files!!\n",
    "train_val_test = []\n",
    "for i, pair in enumerate(train_val_pair):\n",
    "    \n",
    "    # Training and validation files separately\n",
    "    train_tmp, val_tmp = train_val_pair[i][0], train_val_pair[i][1]\n",
    "    \n",
    "    # Get the split number of training file\n",
    "    split_num = re.search('_((\\w*)_\\d)', pair[0])\n",
    "    split_nums.append(str(split_num.group(1) + '.yaml')) # For yaml files!!\n",
    "    \n",
    "    train_split_num = split_num.group(2)\n",
    "    for test_tmp in test_files:\n",
    "        # Get the split number of testing file\n",
    "        test_split_num = re.search('_(\\w*)', test_tmp).group(1)\n",
    "        \n",
    "        # If same split number in training, validation and prediction, combine\n",
    "        if train_split_num == test_split_num:\n",
    "            train_val_test.append([train_tmp, val_tmp, test_tmp])\n",
    "            \n",
    "print('Training, validation and testing pairs')\n",
    "print(*train_val_test, sep='\\n')\n",
    "print()\n",
    "\n",
    "print('Total of {} training, validation and testing sets'.format(len(train_val_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d9d870",
   "metadata": {},
   "source": [
    "From the sets above we are going to create the yaml files. The base of the training yaml is as follows\n",
    "\n",
    "```\n",
    "# INITIAL SETTINGS\n",
    "train_file: train_split0_0.csv\n",
    "val_file: val_split0_0.csv\n",
    "\n",
    "# TRAINING SETTINGS\n",
    "batch_size: 10\n",
    "num_workers: 0\n",
    "\n",
    "# SAVE, LOAD AND DISPLAY INFORMATION\n",
    "epochs: 1\n",
    "\n",
    "```\n",
    "\n",
    "and of the prediction yaml file as follows\n",
    "\n",
    "```\n",
    "# INITIAL SETTINGS\n",
    "test_file: test_split0.csv\n",
    "model: split0_0.pth\n",
    "```\n",
    "\n",
    "*Feel free to set the attributes for training settings and other information as you want in the very first code chunk.* \n",
    "\n",
    "<font color = red>**NOTE!**</font> (*Consider only if you have already created all the csv files of different stratified splits.*) Feel also free to create only a part of the yaml files. All the train-val-test sets are listed in the variable `train_val_test` so it's easy to iterate over only a part of it. If you want to part it, remember to consider `split_nums` too since the yaml files will be named after it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a529496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the train-val-test splits zipped with split numbers\n",
    "# Feel free to manipulate the all-in list!\n",
    "\n",
    "pair_and_split = list(zip(train_val_test, split_nums))\n",
    "\n",
    "# NB! pair_and_split will be then be iterated so you need this\n",
    "#     attribute in the next code chunk (in for-loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c178529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training, validation and testing set is\n",
      "train_split0_0 \t val_split0_0 \t test_split0\n",
      "Yaml file will be named as split0_0.yaml\n",
      "\n",
      "Training, validation and testing set is\n",
      "train_split0_1 \t val_split0_1 \t test_split0\n",
      "Yaml file will be named as split0_1.yaml\n",
      "\n",
      "Training, validation and testing set is\n",
      "train_split0_2 \t val_split0_2 \t test_split0\n",
      "Yaml file will be named as split0_2.yaml\n",
      "\n",
      "Training, validation and testing set is\n",
      "train_split0_3 \t val_split0_3 \t test_split0\n",
      "Yaml file will be named as split0_3.yaml\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ruamel.yaml import YAML\n",
    "import ruamel.yaml\n",
    "import sys\n",
    "  \n",
    "def save_yaml(yaml_str, yaml_path, split):\n",
    "    ''' Save the given string as a yaml file in the given location.\n",
    "    '''\n",
    "    \n",
    "    # Make the yaml directory\n",
    "    if not os.path.isdir(yaml_path):\n",
    "        os.mkdir(yaml_path)\n",
    "    \n",
    "    # Write the yaml file\n",
    "    with open(os.path.join(yaml_path, split), 'w') as yaml_file:\n",
    "        yaml = YAML()\n",
    "        code = yaml.load(yaml_str)\n",
    "        yaml.dump(code, yaml_file)\n",
    "    \n",
    "        \n",
    "def create_testing_yaml(test_csv, split):\n",
    "    ''' Make a yaml file for prediction. The base of it is presented above.\n",
    "    '''\n",
    "    # The name of the model\n",
    "    # e.g. trained with a yaml file ´split0_0_smoke.yaml´\n",
    "    #      model saved as `split0_0_smoke.pth`\n",
    "    model_name = split.split('.')[0] + '.pth'\n",
    "    \n",
    "    yaml_str = '''\\\n",
    "# INITIAL SETTINGS\n",
    "    test_file: {}\n",
    "    model: {}\n",
    "    '''.format(test_csv, model_name)\n",
    "    yaml_path = test_yaml_save_path\n",
    "    save_yaml(yaml_str, yaml_path, split)\n",
    "    \n",
    "\n",
    "def create_training_yaml(train_csv, val_csv, split):\n",
    "    ''' Make a yaml file for training. The base of it is presented above.\n",
    "    '''\n",
    "    yaml_str = '''\\\n",
    "# INITIAL SETTINGS\n",
    "    train_file: {}\n",
    "    val_file: {}\n",
    "\n",
    "# TRAINING SETTINGS\n",
    "    batch_size: {}\n",
    "    num_workers: {}\n",
    "\n",
    "# SAVE, LOAD AND DISPLAY INFORMATION\n",
    "    epochs: {}\n",
    "    '''.format(train_csv, val_csv,\n",
    "              batch_size, num_workers, epochs)\n",
    "    yaml_path = train_yaml_save_path\n",
    "    save_yaml(yaml_str, yaml_path, split)\n",
    "\n",
    "    \n",
    "for pair, split in pair_and_split:\n",
    "    train_tmp, val_tmp, test_tmp = pair[0], pair[1], pair[2]\n",
    "    \n",
    "    print('Training, validation and testing set is')\n",
    "    print(train_tmp.split('.')[0], '\\t', val_tmp.split('.')[0], '\\t', test_tmp.split('.')[0])\n",
    "    print('Yaml file will be named as', split)\n",
    "    print()\n",
    "    \n",
    "    # Training yaml file\n",
    "    create_training_yaml(train_tmp, val_tmp, split)\n",
    "    \n",
    "    # Testing yaml file\n",
    "    create_testing_yaml(test_tmp, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9f7428",
   "metadata": {},
   "source": [
    "Now all the yaml files for training, validation and prediction are created! The training yaml files are located in `/configs/training/train_stratified_smoke/` names as `split0_0.yaml`, `split0_1.yaml`. `split0_2.yaml` and `split0_3.yaml`, and the prediction yaml files in `/configs/predicting/prediction_stratified_smoke/` named with the same names.\n",
    "\n",
    "<font color=red>**NOTE 1!**</font> It is extremely important that in the test yaml file the model is set with the same name as the yaml file which the model is trained with. E.g. when a model is trained using `split0_0.yaml`, it will be saved as `split0_0.pth`. This makes using the repository much easier and simpler. Mind this, if you want to edit the code below.\n",
    "\n",
    "<font color=red>**NOTE 2!**</font> If you are now wondering why the yaml files don't have the csv values --- `train_file`, `val_file` and `test_file` --- in single quotation marks, it's ok. Scripts are able to read and load the values from the yaml files even without those marks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
